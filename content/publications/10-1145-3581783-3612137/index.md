---
title: "LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On"
authors:
  - "Davide Morelli"
  - "Alberto Baldrati"
  - "Giuseppe Cartella"
  - "Marcella Cornia"
  - me
  - "Rita Cucchiara"
date: "2023-01-01T00:00:00Z"
publishDate: "2023-01-01T00:00:00Z"
publication_types: ["paper-conference"]
publication: "Proc. of ACM International Conference on Multimedia (ACM MM)"
publication_short: ""
abstract: "The rapidly evolving fields of e-commerce and metaverse continue to seek innovative approaches to enhance the consumer experience. At the same time, recent advancements in the development of diffusion models have enabled generative networks to create remarkably realistic images. In this context, image-based virtual try-on, which consists in generating a novel image of a target model wearing a given in-shop garment, has yet to capitalize on the potential of these powerful generative solutions. This work introduces LaDI-VTON, the first Latent Diffusion textual Inversion-enhanced model for the Virtual Try-ON task. The proposed architecture relies on a latent diffusion model extended with a novel additional autoencoder module that exploits learnable skip connections to enhance the generation process preserving the model's characteristics. To effectively maintain the texture and details of the in-shop garment, we propose a textual inversion component that can map the visual features of the garment to the CLIP token embedding space and thus generate a set of pseudo-word token embeddings capable of conditioning the generation process. Experimental results on Dress Code and VITON-HD datasets demonstrate that our approach outperforms the competitors by a consistent margin, achieving a significant milestone for the task. Source code and trained models are publicly available at: https://github.com/miccunifi/ladi-vton."
summary: ""
featured: false
hugoblox:
  ids:
    doi: 10.1145/3581783.3612137
links:
  - type: source
    url: "https://doi.org/10.1145/3581783.3612137"
---
