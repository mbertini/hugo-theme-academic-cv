---
title: "OpenFashionCLIP: Vision-and-Language Contrastive Learning with Open-Source Fashion Data"
authors:
  - "Giuseppe Cartella"
  - "Alberto Baldrati"
  - "Davide Morelli"
  - "Marcella Cornia"
  - me
  - "Rita Cucchiara"
date: "2023-01-01T00:00:00Z"
publishDate: "2023-01-01T00:00:00Z"
publication_types: ["paper-conference"]
publication: "Proc. of International Conference on Image Analysis and Processing (ICIAP)"
publication_short: ""
abstract: "The inexorable growth of online shopping and e-commerce demands scalable and robust machine learning-based solutions to accommodate customer requirements. In the context of automatic tagging classification and multimodal retrieval, prior works either defined a low generalizable supervised learning approach or more reusable CLIP-based techniques while, however, training on closed source data. In this work, we propose OpenFashionCLIP, a vision-and-language contrastive learning method that only adopts open-source fashion data stemming from diverse domains, and characterized by varying degrees of specificity. Our approach is extensively validated across several tasks and benchmarks, and experimental results highlight a significant out-of-domain generalization capability and consistent improvements over state-of-the-art methods both in terms of accuracy and recall. Source code and trained models are publicly available at: ."
summary: ""
featured: false
hugoblox:
  ids:
    doi: 10.1007/978-3-031-43148-7_21
links:
  - type: source
    url: "https://doi.org/10.1007/978-3-031-43148-7_21"
---
